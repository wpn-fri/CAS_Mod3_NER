{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model Testing on Custom Text\n",
    "\n",
    "This notebook loads trained BiLSTM models and tests them on custom literary texts.\n",
    "\n",
    "**Requirements:**\n",
    "- Trained models in `../results/` directory\n",
    "- Vocabulary and tag mappings in `../data/` directory\n",
    "\n",
    "**Features:**\n",
    "- Load and test multiple saved models\n",
    "- Predict NER tags on custom text\n",
    "- Visualize entities with color coding\n",
    "- Compare predictions from different models side-by-side\n",
    "- Interactive testing interface\n",
    "- Export predictions to CSV/JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch for model loading and inference\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Import standard libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import for text processing\n",
    "import re\n",
    "\n",
    "# Import for visualization\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Paths and Parameters\n",
    "# ============================================================================\n",
    "\n",
    "# Directory paths\n",
    "DATA_DIR = Path('../data')\n",
    "RESULTS_DIR = Path('../results')\n",
    "OUTPUT_DIR = Path('../output')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Model file paths\n",
    "MODEL_PATHS = {\n",
    "    'Random': RESULTS_DIR / 'BiLSTM_Random_best.pt',\n",
    "    'FastText': RESULTS_DIR / 'BiLSTM_FastText_best.pt'\n",
    "}\n",
    "\n",
    "# Data file paths\n",
    "VOCAB_PATH = DATA_DIR / 'vocabulary.json'\n",
    "TAG_MAPPINGS_PATH = DATA_DIR / 'tag_mappings.json'\n",
    "\n",
    "# Model hyperparameters (must match training configuration)\n",
    "MAX_LEN = 128  # Maximum sequence length\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 3\n",
    "DROPOUT = 0.6\n",
    "BIDIRECTIONAL = True\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Max sequence length: {MAX_LEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Model Architecture\n",
    "\n",
    "Define the same BiLSTM architecture used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM model for Named Entity Recognition.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Embedding layer: Converts word indices to dense vectors\n",
    "    2. Bidirectional LSTM: Processes sequences in both directions\n",
    "    3. Dropout: Regularization to prevent overfitting\n",
    "    4. Fully connected layer: Maps LSTM outputs to tag scores\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags, \n",
    "                 num_layers=2, dropout=0.5, pretrained_embeddings=None):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "        \n",
    "        # Save dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Embedding layer\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding = nn.Embedding.from_pretrained(\n",
    "                pretrained_embeddings, \n",
    "                freeze=False,  # Allow fine-tuning\n",
    "                padding_idx=0  # <PAD> token\n",
    "            )\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(\n",
    "                vocab_size, \n",
    "                embedding_dim, \n",
    "                padding_idx=0\n",
    "            )\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Fully connected layer (hidden_dim * 2 because bidirectional)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_tags)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of word indices, shape (batch_size, seq_len)\n",
    "        \n",
    "        Returns:\n",
    "            Tag scores, shape (batch_size, seq_len, num_tags)\n",
    "        \"\"\"\n",
    "        # Embed words: (batch_size, seq_len) -> (batch_size, seq_len, embedding_dim)\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # Apply dropout to embeddings\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # LSTM forward pass: (batch_size, seq_len, embedding_dim) -> (batch_size, seq_len, hidden_dim * 2)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        \n",
    "        # Apply dropout to LSTM outputs\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        # Fully connected layer: (batch_size, seq_len, hidden_dim * 2) -> (batch_size, seq_len, num_tags)\n",
    "        tag_scores = self.fc(lstm_out)\n",
    "        \n",
    "        return tag_scores\n",
    "\n",
    "print(\"BiLSTMTagger model architecture defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Resources\n",
    "\n",
    "Load vocabulary, tag mappings, and trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "print(\"Loading vocabulary...\")\n",
    "with open(VOCAB_PATH, 'r') as f:\n",
    "    vocab_data = json.load(f)\n",
    "    word2idx = vocab_data['word2idx']\n",
    "    vocab_size = vocab_data['vocab_size']\n",
    "\n",
    "print(f\"  Vocabulary size: {vocab_size:,}\")\n",
    "\n",
    "# Load tag mappings\n",
    "print(\"\\nLoading tag mappings...\")\n",
    "with open(TAG_MAPPINGS_PATH, 'r') as f:\n",
    "    tag_data = json.load(f)\n",
    "    tag2idx = tag_data['tag2idx']\n",
    "    idx2tag = {int(k): v for k, v in tag_data['idx2tag'].items()}  # Convert keys to int\n",
    "    PAD_TAG_IDX = tag_data['PAD_TAG_IDX']\n",
    "\n",
    "num_tags = len(tag2idx)\n",
    "print(f\"  Number of tags: {num_tags}\")\n",
    "print(f\"  Tags: {list(tag2idx.keys())}\")\n",
    "\n",
    "# Load models\n",
    "models = {}\n",
    "print(\"\\nLoading models...\")\n",
    "\n",
    "for model_name, model_path in MODEL_PATHS.items():\n",
    "    if model_path.exists():\n",
    "        # Create model instance\n",
    "        model = BiLSTMTagger(\n",
    "            vocab_size=vocab_size,\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            num_tags=num_tags,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            dropout=DROPOUT,\n",
    "            pretrained_embeddings=None\n",
    "        )\n",
    "        \n",
    "        # Load saved weights\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.to(device)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        models[model_name] = model\n",
    "        print(f\"  ✓ Loaded {model_name} model from {model_path.name}\")\n",
    "    else:\n",
    "        print(f\"  ✗ Model file not found: {model_path}\")\n",
    "\n",
    "if not models:\n",
    "    print(\"\\n⚠ WARNING: No models loaded! Please ensure model files exist in ../results/\")\n",
    "else:\n",
    "    print(f\"\\n✓ Successfully loaded {len(models)} model(s)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESOURCES LOADED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Helper Functions\n",
    "\n",
    "Define functions for prediction, visualization, and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenize(text):\n",
    "    \"\"\"\n",
    "    Simple tokenization that splits on whitespace and punctuation.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "    \n",
    "    Returns:\n",
    "        List of tokens\n",
    "    \"\"\"\n",
    "    # Split on whitespace and punctuation but keep punctuation\n",
    "    tokens = re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def predict_ner(model, text, word2idx, idx2tag, device, max_len=128):\n",
    "    \"\"\"\n",
    "    Predict NER tags for a given text using a trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained BiLSTM model\n",
    "        text: Input text string\n",
    "        word2idx: Dictionary mapping words to indices\n",
    "        idx2tag: Dictionary mapping tag indices to tag names\n",
    "        device: torch device (cpu or cuda)\n",
    "        max_len: Maximum sequence length (default: 128)\n",
    "    \n",
    "    Returns:\n",
    "        List of (token, tag) tuples\n",
    "    \"\"\"\n",
    "    # Tokenize the input text\n",
    "    tokens = simple_tokenize(text)\n",
    "    \n",
    "    if not tokens:\n",
    "        return []\n",
    "    \n",
    "    # Truncate if necessary\n",
    "    original_length = len(tokens)\n",
    "    tokens = tokens[:max_len]\n",
    "    \n",
    "    # Convert tokens to indices (use <UNK> for unknown words)\n",
    "    unk_idx = word2idx.get('<UNK>', 1)\n",
    "    token_indices = [word2idx.get(token.lower(), unk_idx) for token in tokens]\n",
    "    \n",
    "    # Pad sequence to max_len\n",
    "    if len(token_indices) < max_len:\n",
    "        token_indices += [0] * (max_len - len(token_indices))  # 0 is <PAD>\n",
    "    \n",
    "    # Convert to tensor and add batch dimension\n",
    "    input_tensor = torch.tensor([token_indices], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tag_scores = model(input_tensor)  # (1, max_len, num_tags)\n",
    "        predictions = torch.argmax(tag_scores, dim=2)  # (1, max_len)\n",
    "    \n",
    "    # Convert predictions to tags (only for original tokens, not padding)\n",
    "    predicted_tags = [idx2tag[idx.item()] for idx in predictions[0][:len(tokens)]]\n",
    "    \n",
    "    # Create (token, tag) pairs\n",
    "    result = list(zip(tokens, predicted_tags))\n",
    "    \n",
    "    if original_length > max_len:\n",
    "        print(f\"⚠ Note: Text truncated from {original_length} to {max_len} tokens\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def get_entity_color(tag):\n",
    "    \"\"\"\n",
    "    Get color for entity tag visualization.\n",
    "    \n",
    "    Args:\n",
    "        tag: NER tag (e.g., 'B-PER', 'I-LOC', 'O')\n",
    "    \n",
    "    Returns:\n",
    "        HTML color code\n",
    "    \"\"\"\n",
    "    color_map = {\n",
    "        'PER': '#FFB6C1',  # Light pink for persons\n",
    "        'LOC': '#ADD8E6',  # Light blue for locations\n",
    "        'GPE': '#90EE90',  # Light green for geopolitical entities\n",
    "        'ORG': '#FFD700',  # Gold for organizations\n",
    "        'FAC': '#DDA0DD',  # Plum for facilities\n",
    "        'VEH': '#F0E68C',  # Khaki for vehicles\n",
    "    }\n",
    "    \n",
    "    # Extract entity type from tag (e.g., 'B-PER' -> 'PER')\n",
    "    if tag == 'O':\n",
    "        return None\n",
    "    \n",
    "    entity_type = tag.split('-')[-1] if '-' in tag else tag\n",
    "    return color_map.get(entity_type, '#D3D3D3')  # Default gray\n",
    "\n",
    "\n",
    "def visualize_entities(predictions, show_all=False):\n",
    "    \"\"\"\n",
    "    Visualize NER predictions with color-coded entity types.\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of (token, tag) tuples\n",
    "        show_all: If True, show all tokens including 'O' tags (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        HTML display of colored entities\n",
    "    \"\"\"\n",
    "    if not predictions:\n",
    "        print(\"No predictions to visualize.\")\n",
    "        return\n",
    "    \n",
    "    html_parts = []\n",
    "    \n",
    "    for token, tag in predictions:\n",
    "        color = get_entity_color(tag)\n",
    "        \n",
    "        if color:\n",
    "            # Entity token - highlight with color\n",
    "            html_parts.append(\n",
    "                f'<span style=\"background-color: {color}; padding: 2px 4px; '\n",
    "                f'margin: 2px; border-radius: 3px; font-weight: bold;\"'\n",
    "                f'title=\"{tag}\">{token}</span>'\n",
    "            )\n",
    "        elif show_all:\n",
    "            # Non-entity token - show without highlighting\n",
    "            html_parts.append(f'<span style=\"margin: 2px;\">{token}</span>')\n",
    "    \n",
    "    # Display HTML\n",
    "    html = '<div style=\"line-height: 2.5; font-size: 14px;\">' + ' '.join(html_parts) + '</div>'\n",
    "    display(HTML(html))\n",
    "    \n",
    "    # Create legend\n",
    "    legend_html = '<div style=\"margin-top: 15px; font-size: 12px;\"><b>Legend:</b> '\n",
    "    legend_items = [\n",
    "        ('PER', 'Person', '#FFB6C1'),\n",
    "        ('LOC', 'Location', '#ADD8E6'),\n",
    "        ('GPE', 'Geo-Political Entity', '#90EE90'),\n",
    "        ('ORG', 'Organization', '#FFD700'),\n",
    "        ('FAC', 'Facility', '#DDA0DD'),\n",
    "        ('VEH', 'Vehicle', '#F0E68C')\n",
    "    ]\n",
    "    \n",
    "    for code, name, color in legend_items:\n",
    "        legend_html += (\n",
    "            f'<span style=\"background-color: {color}; padding: 2px 8px; '\n",
    "            f'margin: 2px; border-radius: 3px; font-weight: bold;\">{code}</span> '\n",
    "            f'<span style=\"margin-right: 10px;\">{name}</span> '\n",
    "        )\n",
    "    legend_html += '</div>'\n",
    "    display(HTML(legend_html))\n",
    "\n",
    "\n",
    "def compare_models(text, models, word2idx, idx2tag, device, max_len=128):\n",
    "    \"\"\"\n",
    "    Compare predictions from multiple models side-by-side.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text string\n",
    "        models: Dictionary of model_name -> model\n",
    "        word2idx: Dictionary mapping words to indices\n",
    "        idx2tag: Dictionary mapping tag indices to tag names\n",
    "        device: torch device (cpu or cuda)\n",
    "        max_len: Maximum sequence length (default: 128)\n",
    "    \"\"\"\n",
    "    if not models:\n",
    "        print(\"No models available for comparison.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nInput text: {text}\")\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    \n",
    "    # Get predictions from all models\n",
    "    all_predictions = {}\n",
    "    for model_name, model in models.items():\n",
    "        predictions = predict_ner(model, text, word2idx, idx2tag, device, max_len)\n",
    "        all_predictions[model_name] = predictions\n",
    "    \n",
    "    # Display each model's predictions\n",
    "    for model_name, predictions in all_predictions.items():\n",
    "        print(f\"\\n{model_name} Model:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Show entities only\n",
    "        entities = [(token, tag) for token, tag in predictions if tag != 'O']\n",
    "        \n",
    "        if entities:\n",
    "            print(f\"Found {len(entities)} entities:\")\n",
    "            for token, tag in entities:\n",
    "                print(f\"  {token:20s} -> {tag}\")\n",
    "        else:\n",
    "            print(\"  No entities found.\")\n",
    "        \n",
    "        # Visualize\n",
    "        print(\"\\nVisualization:\")\n",
    "        visualize_entities(predictions)\n",
    "        print()\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "def export_predictions(predictions, output_path, format='csv'):\n",
    "    \"\"\"\n",
    "    Export predictions to CSV or JSON file.\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of (token, tag) tuples\n",
    "        output_path: Path to output file\n",
    "        format: 'csv' or 'json' (default: 'csv')\n",
    "    \"\"\"\n",
    "    # Filter to entities only\n",
    "    entities = [(token, tag) for token, tag in predictions if tag != 'O']\n",
    "    \n",
    "    if format == 'csv':\n",
    "        df = pd.DataFrame(entities, columns=['Token', 'Tag'])\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"✓ Exported {len(entities)} entities to {output_path}\")\n",
    "    \n",
    "    elif format == 'json':\n",
    "        data = [{'token': token, 'tag': tag} for token, tag in entities]\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        print(f\"✓ Exported {len(entities)} entities to {output_path}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"✗ Unsupported format: {format}. Use 'csv' or 'json'.\")\n",
    "\n",
    "\n",
    "print(\"Helper functions defined successfully!\")\n",
    "print(\"  - simple_tokenize()\")\n",
    "print(\"  - predict_ner()\")\n",
    "print(\"  - visualize_entities()\")\n",
    "print(\"  - compare_models()\")\n",
    "print(\"  - export_predictions()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Testing Cell\n",
    "\n",
    "**Modify the text below to test your own literary passages!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INTERACTIVE TESTING - Modify this text to test your own passages\n",
    "# ============================================================================\n",
    "\n",
    "# Enter your custom text here:\n",
    "custom_text = \"Elizabeth Bennet lived in Longbourn with her family. She often visited her friend Charlotte Lucas in the nearby village.\"\n",
    "\n",
    "# Test with one model (change 'FastText' to 'Random' to try the other model)\n",
    "model_name = 'FastText'  # or 'Random'\n",
    "\n",
    "if model_name in models:\n",
    "    print(f\"\\nTesting {model_name} model...\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Input: {custom_text}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = predict_ner(models[model_name], custom_text, word2idx, idx2tag, device, MAX_LEN)\n",
    "    \n",
    "    # Display entities only\n",
    "    entities = [(token, tag) for token, tag in predictions if tag != 'O']\n",
    "    \n",
    "    print(f\"\\nFound {len(entities)} entities:\")\n",
    "    if entities:\n",
    "        for token, tag in entities:\n",
    "            print(f\"  {token:20s} -> {tag}\")\n",
    "    else:\n",
    "        print(\"  No entities found.\")\n",
    "    \n",
    "    # Visualize\n",
    "    print(\"\\nVisualization:\")\n",
    "    visualize_entities(predictions)\n",
    "    \n",
    "    # Optional: Export to file\n",
    "    # export_predictions(predictions, OUTPUT_DIR / 'my_predictions.csv', format='csv')\n",
    "    \n",
    "else:\n",
    "    print(f\"Model '{model_name}' not found. Available models: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Testing on Sample Texts\n",
    "\n",
    "Test multiple sample literary texts and compare model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAMPLE LITERARY TEXTS FOR TESTING\n",
    "# ============================================================================\n",
    "\n",
    "sample_texts = [\n",
    "    \"Elizabeth Bennet lived in Longbourn.\",\n",
    "    \"Sherlock Holmes resided at 221B Baker Street in London.\",\n",
    "    \"Captain Ahab commanded the whaling ship Pequod.\",\n",
    "    \"Hester Prynne lived in Boston during the Puritan era.\",\n",
    "    \"Jay Gatsby threw lavish parties at his mansion in West Egg, New York.\",\n",
    "    \"Atticus Finch practiced law in the town of Maycomb, Alabama.\",\n",
    "    \"Holden Caulfield was expelled from Pencey Prep and wandered around New York City.\",\n",
    "    \"The March sisters lived in Concord, Massachusetts during the Civil War.\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH TESTING ON SAMPLE LITERARY TEXTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Sample {i}/{len(sample_texts)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    compare_models(text, models, word2idx, idx2tag, device, MAX_LEN)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH TESTING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detailed Comparison on Single Text\n",
    "\n",
    "Choose one text for detailed side-by-side comparison of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a text for detailed comparison\n",
    "detailed_text = \"In the spring of 1922, Jay Gatsby moved into a mansion in West Egg, Long Island, where he threw elaborate parties. His neighbor Nick Carraway often observed the festivities from his small cottage.\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "compare_models(detailed_text, models, word2idx, idx2tag, device, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Predictions (Optional)\n",
    "\n",
    "Export predictions to CSV or JSON format for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Export predictions from one model to CSV\n",
    "\n",
    "# Choose text and model\n",
    "export_text = \"Sherlock Holmes and Dr. Watson investigated a case at Buckingham Palace in London.\"\n",
    "export_model_name = 'FastText'  # or 'Random'\n",
    "\n",
    "if export_model_name in models:\n",
    "    # Get predictions\n",
    "    predictions = predict_ner(models[export_model_name], export_text, word2idx, idx2tag, device, MAX_LEN)\n",
    "    \n",
    "    # Export to CSV\n",
    "    csv_path = OUTPUT_DIR / f'{export_model_name}_predictions.csv'\n",
    "    export_predictions(predictions, csv_path, format='csv')\n",
    "    \n",
    "    # Export to JSON\n",
    "    json_path = OUTPUT_DIR / f'{export_model_name}_predictions.json'\n",
    "    export_predictions(predictions, json_path, format='json')\n",
    "    \n",
    "    print(f\"\\nPredictions exported to:\")\n",
    "    print(f\"  - {csv_path}\")\n",
    "    print(f\"  - {json_path}\")\n",
    "else:\n",
    "    print(f\"Model '{export_model_name}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics\n",
    "\n",
    "Display summary statistics about model predictions across all sample texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze predictions across all sample texts\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stats = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name} Model:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_entities = 0\n",
    "    entity_types = defaultdict(int)\n",
    "    \n",
    "    for text in sample_texts:\n",
    "        predictions = predict_ner(model, text, word2idx, idx2tag, device, MAX_LEN)\n",
    "        \n",
    "        for token, tag in predictions:\n",
    "            if tag != 'O':\n",
    "                total_entities += 1\n",
    "                # Extract entity type (e.g., 'B-PER' -> 'PER')\n",
    "                entity_type = tag.split('-')[-1] if '-' in tag else tag\n",
    "                entity_types[entity_type] += 1\n",
    "    \n",
    "    print(f\"Total entities found: {total_entities}\")\n",
    "    print(f\"\\nEntity type distribution:\")\n",
    "    for entity_type, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / total_entities * 100) if total_entities > 0 else 0\n",
    "        print(f\"  {entity_type:10s}: {count:3d} ({percentage:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
