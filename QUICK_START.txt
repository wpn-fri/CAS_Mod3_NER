================================================================================
QUICK START GUIDE: litbank_ner_fasttext.ipynb
================================================================================

WHAT WAS DONE:
--------------
Created a modified version of litbank_ner_wpn.ipynb that uses FastText
embeddings instead of GloVe embeddings.

KEY CHANGES:
------------
1. Sections 1-6: IDENTICAL to original (no changes)
2. Section 7: Loads FastText embeddings using gensim (300 dimensions)
3. Section 10: Initializes two models (Random vs FastText)
4. Sections 11-17: Updated variable names (GloVe â†’ FastText)

WHAT THE NOTEBOOK DOES:
------------------------
Trains and compares TWO BiLSTM models for Named Entity Recognition:
  - Model 1: Randomly initialized embeddings
  - Model 2: Pre-trained FastText embeddings (300d)

Both models have identical architecture except for embedding initialization.

BEFORE RUNNING:
---------------
1. Install required packages:
   pip install torch transformers datasets gensim seqeval scikit-learn matplotlib pandas tqdm

2. Ensure you have:
   - Internet connection (for downloading FastText on first run)
   - ~1.5 GB free disk space (for FastText model cache)
   - GPU recommended (but CPU works too)

RUNNING THE NOTEBOOK:
---------------------
1. Open: notebooks/litbank_ner_fasttext.ipynb

2. First Run:
   - FastText will download automatically (~1 GB)
   - Takes 5-10 minutes depending on internet speed
   - Downloaded model is cached for future use

3. Subsequent Runs:
   - Uses cached FastText model (much faster)
   - Training takes ~10-30 minutes depending on hardware

4. Output:
   - Training progress visualization
   - Performance comparison (Random vs FastText)
   - Confusion matrices
   - Per-entity metrics
   - Saved models in ../results/

HYPERPARAMETER EXPERIMENTATION:
--------------------------------
All hyperparameters are at the top of their sections for easy modification:

SECTION 7 - Embeddings:
  EMBEDDING_DIM = 300     # Must match FastText (don't change)
  RANDOM_SEED = 42        # For reproducibility

SECTION 10 - Model Architecture:
  HIDDEN_DIM = 256        # Try: 128, 256, 512
  NUM_LAYERS = 2          # Try: 1, 2, 3
  DROPOUT = 0.3           # Try: 0.0, 0.3, 0.5
  BIDIRECTIONAL = True    # Try: True, False
  FREEZE_EMBEDDINGS = False  # Try: True (freeze FastText), False (fine-tune)

SECTION 12 - Training:
  NUM_EPOCHS = 10         # Try: 5, 10, 15, 20
  LEARNING_RATE = 0.001   # Try: 0.0001, 0.001, 0.01
  BATCH_SIZE = 32         # Defined in Section 8

To experiment:
  1. Modify hyperparameter values
  2. Re-run from that section onwards
  3. Compare results

CODE STRUCTURE:
---------------
Each major section has:
  1. Markdown header explaining the purpose
  2. Hyperparameters at the top (clearly labeled)
  3. Extensive comments explaining each step
  4. Visual separators (==== and ----)
  5. Output displaying progress and results

Comments are beginner-friendly and explain:
  - What each code block does
  - Why certain choices were made
  - What parameters control
  - Typical value ranges
  - Advantages and disadvantages

EXPECTED RESULTS:
-----------------
FastText embeddings typically outperform random embeddings:
  - Higher F1 scores (especially on rare entities)
  - Better handling of unusual words
  - Faster convergence during training
  - More robust to vocabulary variations

However, the trade-off is:
  - Larger model size (300d vs 100d or smaller)
  - Slower training and inference
  - More memory usage

TROUBLESHOOTING:
----------------
1. "No internet connection" error:
   - FastText download requires internet
   - If download fails, try again or use cached version

2. "CUDA out of memory" error:
   - Reduce BATCH_SIZE in Section 8
   - Use smaller HIDDEN_DIM in Section 10
   - Run on CPU instead (set device = 'cpu')

3. "Import error" for gensim:
   - Run: pip install gensim

4. Poor performance:
   - Try increasing NUM_EPOCHS
   - Try adjusting LEARNING_RATE
   - Check if embeddings are frozen (FREEZE_EMBEDDINGS)

DOCUMENTATION:
--------------
See these files for more details:
  1. CONVERSION_SUMMARY.txt - Full conversion details
  2. FASTTEXT_IMPLEMENTATION.md - Implementation comparison
  3. This file (QUICK_START.txt) - Quick reference

COMPARISON WITH ORIGINAL:
--------------------------
Original notebook (litbank_ner_wpn.ipynb):
  - Uses GloVe embeddings (100 dimensions)
  - Loads from local text file
  - Hardcoded hyperparameters
  - Basic comments

New notebook (litbank_ner_fasttext.ipynb):
  - Uses FastText embeddings (300 dimensions)
  - Downloads via gensim API
  - Organized hyperparameters at top
  - Extensive beginner-friendly comments
  - Better code organization

================================================================================
Ready to start! Open the notebook and run all cells.
================================================================================
